{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook explores building the **customer churn model** and an **interpretability model** to explain each prediction.\n",
    "In addition to making a prediction of whether a customer will churn, we will also be able to answer the question, \"why are they expected to churn?\"\n",
    "\n",
    "The following work will look fairly standard to anyone having trained machine learning models using python Jupyter notebooks.\n",
    "The CML platform provides a **fully capable Jupyter notebook environment** that data scientists know and love.\n",
    "\n",
    "If you haven't yet, run through the initialization steps in the README file and Part 1. \n",
    "In Part 1, the data is imported into the `default.telco_churn` table in Hive. All data accesses fetch from Hive.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "We again start by creating a `SparkSession` to fetch the data using Spark SQL, only this time we convert to a pandas `DataFrame` since we saw earlier that there are only 7k records in the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- customerID: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- SeniorCitizen: string (nullable = true)\n",
      " |-- Partner: string (nullable = true)\n",
      " |-- Dependents: string (nullable = true)\n",
      " |-- tenure: double (nullable = true)\n",
      " |-- PhoneService: string (nullable = true)\n",
      " |-- MultipleLines: string (nullable = true)\n",
      " |-- InternetService: string (nullable = true)\n",
      " |-- OnlineSecurity: string (nullable = true)\n",
      " |-- OnlineBackup: string (nullable = true)\n",
      " |-- DeviceProtection: string (nullable = true)\n",
      " |-- TechSupport: string (nullable = true)\n",
      " |-- StreamingTV: string (nullable = true)\n",
      " |-- StreamingMovies: string (nullable = true)\n",
      " |-- Contract: string (nullable = true)\n",
      " |-- PaperlessBilling: string (nullable = true)\n",
      " |-- PaymentMethod: string (nullable = true)\n",
      " |-- MonthlyCharges: double (nullable = true)\n",
      " |-- TotalCharges: double (nullable = true)\n",
      " |-- Churn: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession\\\n",
    "    .builder\\\n",
    "    .appName(\"PythonSQL\")\\\n",
    "    .master(\"local[*]\")\\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark_df = spark.sql(\"SELECT * FROM default.telco_churn\")\n",
    "spark_df.printSchema()\n",
    "df = spark_df.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** If you don't have the Hive table, you can read the csv from the CML filesystem using pandas directly:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "data_dir = '/home/cdsw'\n",
    "df = pd.read_csv(os.path.join(data_dir, 'raw', 'WA_Fn-UseC_-Telco-Customer-Churn-.csv'))\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic feature engineering\n",
    "\n",
    "\n",
    "Next we munge the data into appropriate types for later steps. \n",
    "In particular, we want to convert all the binary and string columns into pandas `Categorical` types.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess, glob, sys\n",
    "import dill  # a better pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data_dir = '/home/cdsw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "idcol = 'customerID'  # ID column\n",
    "labelcol = 'Churn'  # label column\n",
    "cols = (('gender', True),  # (feature column, Categorical?)\n",
    "        ('SeniorCitizen', True),\n",
    "        ('Partner', True),\n",
    "        ('Dependents', True),\n",
    "        ('tenure', False),\n",
    "        ('PhoneService', True),\n",
    "        ('MultipleLines', True),\n",
    "        ('InternetService', True),\n",
    "        ('OnlineSecurity', True),\n",
    "        ('OnlineBackup', True),\n",
    "        ('DeviceProtection', True),\n",
    "        ('TechSupport', True),\n",
    "        ('StreamingTV', True),\n",
    "        ('StreamingMovies', True),\n",
    "        ('Contract', True),\n",
    "        ('PaperlessBilling', True),\n",
    "        ('PaymentMethod', True),\n",
    "        ('MonthlyCharges', False),\n",
    "        ('TotalCharges', False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>tenure</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>InternetService</th>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <th>OnlineBackup</th>\n",
       "      <th>DeviceProtection</th>\n",
       "      <th>TechSupport</th>\n",
       "      <th>StreamingTV</th>\n",
       "      <th>StreamingMovies</th>\n",
       "      <th>Contract</th>\n",
       "      <th>PaperlessBilling</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>29.85</td>\n",
       "      <td>29.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>34.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>56.95</td>\n",
       "      <td>1889.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>53.85</td>\n",
       "      <td>108.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>45.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Bank transfer (automatic)</td>\n",
       "      <td>42.30</td>\n",
       "      <td>1840.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>70.70</td>\n",
       "      <td>151.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    gender SeniorCitizen Partner Dependents  tenure PhoneService  \\\n",
       "id                                                                 \n",
       "0   Female             0     Yes         No     1.0           No   \n",
       "1     Male             0      No         No    34.0          Yes   \n",
       "2     Male             0      No         No     2.0          Yes   \n",
       "3     Male             0      No         No    45.0           No   \n",
       "4   Female             0      No         No     2.0          Yes   \n",
       "\n",
       "       MultipleLines InternetService OnlineSecurity OnlineBackup  \\\n",
       "id                                                                 \n",
       "0   No phone service             DSL             No          Yes   \n",
       "1                 No             DSL            Yes           No   \n",
       "2                 No             DSL            Yes          Yes   \n",
       "3   No phone service             DSL            Yes           No   \n",
       "4                 No     Fiber optic             No           No   \n",
       "\n",
       "   DeviceProtection TechSupport StreamingTV StreamingMovies        Contract  \\\n",
       "id                                                                            \n",
       "0                No          No          No              No  Month-to-month   \n",
       "1               Yes          No          No              No        One year   \n",
       "2                No          No          No              No  Month-to-month   \n",
       "3               Yes         Yes          No              No        One year   \n",
       "4                No          No          No              No  Month-to-month   \n",
       "\n",
       "   PaperlessBilling              PaymentMethod  MonthlyCharges  TotalCharges  \n",
       "id                                                                            \n",
       "0               Yes           Electronic check           29.85         29.85  \n",
       "1                No               Mailed check           56.95       1889.50  \n",
       "2               Yes               Mailed check           53.85        108.15  \n",
       "3                No  Bank transfer (automatic)           42.30       1840.75  \n",
       "4               Yes           Electronic check           70.70        151.65  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.replace(r'^\\s$', np.nan, regex=True).dropna().reset_index()  # drop blank rows\n",
    "df.index.name = 'id'  # name the index\n",
    "data, labels = df.drop(labelcol, axis=1), df[labelcol]  # separate out the labels\n",
    "data = data[[c for c, _ in cols]]  # only use the columns named in `cols`\n",
    "data = data.replace({'SeniorCitizen': {1: 'Yes', 0: 'No'}})  # Change 1/0 to Yes/No to match the other binary features\n",
    "\n",
    "# convert the categorical columns to pd.Categorical form\n",
    "for col, iscat in cols:\n",
    "    if iscat:\n",
    "        data[col] = pd.Categorical(data[col])\n",
    "labels = (labels == 'Yes')  # convert labels from str to bool\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine learning model\n",
    "\n",
    "This step follows a fairly standard ML workflow, which is to create a pipeline to:\n",
    "\n",
    "* Encode the categorical features as numeric\n",
    "* Normalize the numeric features\n",
    "* Train a classification model using these processed features\n",
    "\n",
    "We use *one-hot encoding*, *standardization*, and *logistic regression with cross-validation* for the three steps.\n",
    "Then we can evaluate the model's performance.\n",
    "\n",
    "Note: `CategoricalEncoder` and, later, `ExplainedModel` are helper classes pulled and edited from the original CFFL [interpretability report code](https://ff06-2020.fastforwardlabs.com/).\n",
    "You can inspect `churnexplainer.py` to see what they do under the hood.\n",
    "CML lets you continue to write modular code to keep things segregated and clean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-7-4bd95557f75f>\", line 1, in <module>\n",
      "    from sklearn.model_selection import train_test_split\n",
      "  File \"/home/cdsw/.local/lib/python3.6/site-packages/sklearn/model_selection/__init__.py\", line 19, in <module>\n",
      "    from ._validation import cross_val_score\n",
      "  File \"/home/cdsw/.local/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 27, in <module>\n",
      "    from ..metrics.scorer import check_scoring, _check_multimetric_scoring\n",
      "  File \"/home/cdsw/.local/lib/python3.6/site-packages/sklearn/metrics/__init__.py\", line 7, in <module>\n",
      "    from .ranking import auc\n",
      "  File \"/home/cdsw/.local/lib/python3.6/site-packages/sklearn/metrics/ranking.py\", line 35, in <module>\n",
      "    from ..preprocessing import label_binarize\n",
      "  File \"/home/cdsw/.local/lib/python3.6/site-packages/sklearn/preprocessing/__init__.py\", line 6, in <module>\n",
      "    from ._function_transformer import FunctionTransformer\n",
      "  File \"/home/cdsw/.local/lib/python3.6/site-packages/sklearn/preprocessing/_function_transformer.py\", line 5, in <module>\n",
      "    from ..utils.testing import assert_allclose_dense_sparse\n",
      "  File \"/home/cdsw/.local/lib/python3.6/site-packages/sklearn/utils/testing.py\", line 718, in <module>\n",
      "    import pytest\n",
      "  File \"/opt/cloudera/parcels/Anaconda/lib/python3.6/site-packages/pytest.py\", line 13, in <module>\n",
      "    from _pytest.fixtures import fixture, yield_fixture\n",
      "  File \"/opt/cloudera/parcels/Anaconda/lib/python3.6/site-packages/_pytest/fixtures.py\", line 842, in <module>\n",
      "    class FixtureFunctionMarker(object):\n",
      "  File \"/opt/cloudera/parcels/Anaconda/lib/python3.6/site-packages/_pytest/fixtures.py\", line 844, in FixtureFunctionMarker\n",
      "    params = attr.ib(convert=attr.converters.optional(tuple))\n",
      "TypeError: attrib() got an unexpected keyword argument 'convert'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 1821, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1132, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 358, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/usr/local/lib/python3.6/inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/usr/local/lib/python3.6/inspect.py\", line 1448, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/usr/local/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/usr/local/lib/python3.6/inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"/opt/cloudera/parcels/Anaconda/lib/python3.6/site-packages/py/_vendored_packages/apipkg.py\", line 195, in __getattribute__\n",
      "    return getattr(getmod(), name)\n",
      "  File \"/opt/cloudera/parcels/Anaconda/lib/python3.6/site-packages/py/_vendored_packages/apipkg.py\", line 179, in getmod\n",
      "    x = importobj(modpath, None)\n",
      "  File \"/opt/cloudera/parcels/Anaconda/lib/python3.6/site-packages/py/_vendored_packages/apipkg.py\", line 69, in importobj\n",
      "    module = __import__(modpath, None, None, ['__doc__'])\n",
      "  File \"/opt/cloudera/parcels/Anaconda/lib/python3.6/site-packages/pytest.py\", line 13, in <module>\n",
      "    from _pytest.fixtures import fixture, yield_fixture\n",
      "  File \"/opt/cloudera/parcels/Anaconda/lib/python3.6/site-packages/_pytest/fixtures.py\", line 842, in <module>\n",
      "    class FixtureFunctionMarker(object):\n",
      "  File \"/opt/cloudera/parcels/Anaconda/lib/python3.6/site-packages/_pytest/fixtures.py\", line 844, in FixtureFunctionMarker\n",
      "    params = attr.ib(convert=attr.converters.optional(tuple))\n",
      "TypeError: attrib() got an unexpected keyword argument 'convert'\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "attrib() got an unexpected keyword argument 'convert'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from churnexplainer import CategoricalEncoder  # convert Categorical columns into numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ce = CategoricalEncoder()\n",
    "X = ce.fit_transform(data)  # Categorical columns now have values 0 to num_categories-1\n",
    "y = labels.values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "cat_cols = list(ce.cat_columns_ix_.values())  # indices of the categorical columns (now numeric)\n",
    "ct = ColumnTransformer(\n",
    "    [('ohe', OneHotEncoder(), cat_cols)],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "clf = LogisticRegressionCV(cv=5,solver='lbfgs', max_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('ct', ct),  # 1. Encode the categorical features as numeric\n",
    "                 ('scaler', StandardScaler()),  # 2. Normalize the numeric features\n",
    "                 ('clf', clf)])  # 3. Train a classification model using these processed features\n",
    "pipe.fit(X_train, y_train)\n",
    "train_score = pipe.score(X_train, y_train)\n",
    "test_score = pipe.score(X_test, y_test)\n",
    "print(\"train\",train_score)\n",
    "print(\"test\", test_score)    \n",
    "print(classification_report(y_test, pipe.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare with Random Forest\n",
    "Just for a comparison, lets compare this model to a Random Forest model.\n",
    "This is simpler since Random Forests do not need the categorical features encoded with a `OneHotEncoder`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf_rf = RandomForestClassifier(n_estimators=100)\n",
    "pipe_rf = Pipeline([('scaler', StandardScaler()),\n",
    "                 ('clf', clf_rf)])\n",
    "pipe_rf.fit(X_train, y_train)\n",
    "train_score = pipe_rf.score(X_train, y_train)\n",
    "test_score = pipe_rf.score(X_test, y_test)\n",
    "print(\"train\",train_score)\n",
    "print(\"test\", test_score)\n",
    "print(classification_report(y_test, pipe_rf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot ROC Curve\n",
    "\n",
    "We can also generate an ROC Curve to visualize the model's performance and calculate the AUROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from matplotlib import pyplot\n",
    "\n",
    "logistic_regression_probabilities = pipe.predict_proba(X_test)\n",
    "logistic_regression_probabilities = logistic_regression_probabilities[:, 1]\n",
    "logistic_regression_auc = roc_auc_score(y_test, logistic_regression_probabilities)\n",
    "print('Logistic: AUROC=%.3f' % (logistic_regression_auc))\n",
    "logistic_regression_fpr, logistic_regression_tpr, _ = roc_curve(y_test, logistic_regression_probabilities)\n",
    "pyplot.plot(logistic_regression_fpr, logistic_regression_tpr, label='Logistic')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find an AUC of 0.83. Not bad for a quick exercise without fine tuning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretability model\n",
    "We use [lime](https://github.com/marcotcr/lime) (Local Interpretable Model-Agnostic Explanations) to explain the predictions.\n",
    "It is a method of determining which feature has the greatest effect on the predicted value,\n",
    "and is explained in depth in the the [FFL report](https://ff06-2020.fastforwardlabs.com/).\n",
    "For more information, refer to the [lime documentation](https://lime-ml.readthedocs.io/en/latest/lime.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "\n",
    "data[labels.name + ' probability'] = pipe.predict_proba(X)[:, 1]\n",
    "\n",
    "# List of length number of features, containing names of features in order\n",
    "# in which they appear in X\n",
    "feature_names = list(ce.columns_)\n",
    "\n",
    "# List of indices of columns of X containing categorical features\n",
    "categorical_features = list(ce.cat_columns_ix_.values())\n",
    "\n",
    "# List of (index, [cat1, cat2...]) index-strings tuples, where each index\n",
    "# is that of a categorical column in X, and the list of strings are the\n",
    "# possible values it can take\n",
    "categorical_names = {i: ce.classes_[c]\n",
    "                     for c, i in ce.cat_columns_ix_.items()}\n",
    "class_names = ['No ' + labels.name, labels.name]\n",
    "explainer = LimeTabularExplainer(ce.transform(data),\n",
    "                                 feature_names=feature_names,\n",
    "                                 class_names=class_names,\n",
    "                                 categorical_features=categorical_features,\n",
    "                                 categorical_names=categorical_names)    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explaining a Single Prediction\n",
    "\n",
    "Let's look at how one specfic prediction would be interpreted.\n",
    "Lime explains the prediction by giving every feature a weight from -1 to 1.\n",
    "Features with weights closer to -1 have a stronger impact in coming up with a 0 prediction result (will not churn) and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sample().T  # reminder of the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = explainer.explain_instance(ce.transform(data.sample())[0],pipe.predict_proba)\n",
    "for cols in exp.as_list():\n",
    "    print(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.as_pyplot_figure()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that one of the features that contributes most strongly to the positive prediction is the short tenure of the customer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the model\n",
    "Now that we've done all this work to build the models, we want to be able to use them later.\n",
    "The `ExplainedModel` class is a handy wrapper for using the `CategoricalEncoder`, the `Pipeline` object which *is* the churn model, and the Lime Explainer.\n",
    "Here, we use it to save these trained models for use in later parts of the Project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from churnexplainer import ExplainedModel\n",
    "explainedmodel = ExplainedModel(data=data, labels=labels, model_name='telco_linear',\n",
    "                                categoricalencoder=ce, pipeline=pipe,\n",
    "                                explainer=explainer,data_dir=data_dir)\n",
    "explainedmodel.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrap up\n",
    "We've now covered all the steps to **building a machine learning model** including interpretability\n",
    "and saved our work for use in later sections.\n",
    "\n",
    "In the next part of the series we will explore how to use the **Experiments** feature of CML\n",
    "for when we want to test lots of combinations of hyperparameters to fine tune our models.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
